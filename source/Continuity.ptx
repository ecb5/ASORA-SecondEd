<chapter xmlns:xi="http://www.w3.org/2001/XInclude"  xml:id="Continuity">
  <title>Continuity: What It Isn't and What It Is</title>


  <section  xml:id="Continuity-AnalyticDef">
    <title>An Analytic Definition of Continuity</title>
    <p>
      Before the invention of Calculus, the notion of continuity was
      treated intuitively if it was treated at all.  At first pass, it
      seems a very simple idea based solidly in our experience of the
      real world.  Standing on the bank we see a river flow past us
      continuously, not by tiny jerks.  Even when the flow might seem
      at first to be discontinuous, as when it drops precipitously
      over a cliff, a closer examination shows that it really is not.
      As the water approaches the cliff it speeds up.  When it finally
      goes over it accelerates very quickly but no matter how fast it
      goes it moves continuously, moving from here to there by
      occupying every point in between.  This is continuous motion.
      It never disappears over there and instantaneously reappears
      over here.  That would be discontinuous motion.
    </p>

    <p>
      Similarly, a thrown stone flies continuously (and smoothly) from
      release point to landing point, passing through each point in
      its path.
    </p>

    <p>
      But wait.
    </p>

    <p>
      If the stone passes through discrete points it must be doing so
      by teeny tiny little jerks, mustn't it?  Otherwise how would it
      get from one point to the next?  Is it possible that motion in
      the real world, much like motion in a movie, is really composed
      of tiny jerks from one point to the next but that these tiny
      jerks are simply too small and too fast for our senses to
      detect?
    </p>

    <p>
      If so, then the real world is more like the rational number line
      (<m>\QQ</m>) from <xref ref="NumbersRealRational"></xref>
      than the real number line (<m>\RR</m>).  In that case, motion
      really consists of jumping discretely over the <q>missing</q>
      points (like <m>\sqrt{2}</m>) as we move from here to there.
      That may seem like a bizarre idea to you <mdash /> it does to us
      as well <mdash /> but the idea of continuous motion is equally
      bizarre.  It's just a little harder to see why since it is so
      familiar.
    </p>

    <p>
      The real world will be what it is regardless of what we believe
      it to be, but fortunately in mathematics we are not constrained
      to live in it.  So we won't even try.  We will simply postulate
      that no such jerkiness exists; that all motion is continuous.
    </p>

    <p>
      However we <em>are</em> constrained to live with the logical
      consequences of our assumptions, once they are made.  These will
      lead us into some very deep waters indeed.
    </p>

    <p>
      The intuitive treatment of continuity was maintained throughout
      the 1700's as it was not generally perceived that a truly
      rigorous definition was necessary.  Consider the following
      definition given by Euler in 1748.
    </p>
    <blockquote>
      <p>
        A continuous curve is one such that its nature can be expressed
        by a single function of <m>x.</m> If a curve is of such a nature that for
        its various parts . . . different functions of <m>x</m> are required for its
        expression, . . . , then we call such a curve discontinuous.
      </p>
    </blockquote>
    <p>
      However, the complexities associated with Fourier series and the
      types of functions that they represented caused mathematicians
      in the early <m>1800</m>s to rethink their notions of continuity.  As
      we saw in <xref ref="Interregnum"></xref>, the graph of the
      function defined by the Fourier series
      <me>
        \frac{4}{\pi}\sum_{k=0}^\infty\frac{\left(-1\right)^k}{\left(2k+1\right)} \cos \left(\left(2k+1\right)\pi x\right)
      </me>
      looked like this:
    </p>

    <figure>
      <caption>
      </caption>
      <image width="75%" source="images/Ch5fig1.png" >
        <shortdescription></shortdescription>
      </image>
    </figure>

    <p>
      This function went against Euler<rsq/>s notion of what continuous
      functions should be.  Here, an infinite sum of continuous cosine
      curves provided a single expression which resulted in a
      <q>discontinuous</q> curve.  But as we've seen this didn't
      happen with power series and an intuitive notion of continuity
      is inadequate to explain the difference.  Even more perplexing
      is the following situation.  Intuitively, one would think that a
      continuous curve should have a tangent line at at least one
      point.  It may have a number of jagged points to it, but it
      should be <q>smooth</q> somewhere.  An example of this would be
      <m>f(x)=x^{2/3}</m>.  Its graph is given by
    </p>

    <figure>
      <caption>

      </caption>
      <image width="75%" source="images/Ch5fig2.png" >
        <shortdescription></shortdescription>
      </image>
    </figure>

    <p>
      This function is not differentiable at the origin but it is
      differentiable everywhere else.  One could certainly come up
      with examples of functions which fail to be differentiable at
      any number of points but, intuitively, it would be reasonable
      to expect that a continuous function should be differentiable
      <em>somewhere</em>.  We might conjecture the following:
    </p>

    <conjecture xml:id="conj_ContImplyDiff">
      <statement>
        <p>
          If <m>f</m> is continuous on an interval <m>I</m> then there
          is some <m>a\in I</m>, such that <m>f^\prime(a)</m> exists.
        </p>
      </statement>
    </conjecture>   



    <figure>
      <title></title>
      <caption><url href="https://mathshistory.st-andrews.ac.uk/Biographies/Weierstrass/" visual="mathshistory.st-andrews.ac.uk/Biographies/Weierstrass/">Karl Weierstrass</url> (1815<ndash/>1897)</caption>

      <idx><h>Weierstrass, Karl</h><h>portrait of</h></idx>
      <idx><h>Portraits</h><h>Weierstrass</h></idx>

      <image width="35%" source="images/Weierstrass.png" >
        <shortdescription>Portrait of Karl Weierstrass</shortdescription>
      </image>
    </figure>
    


    <p>

      Surprisingly, in <m>1872</m>, Karl Weierstrass <idx><h>Weierstrass,
      Karl</h></idx> showed that the above conjecture is
      <alert>FALSE</alert>. He did this by displaying the
      counterexample:
      <me>
        f(x)=\sum_{n=0}^\infty b^n\cos(a^n\pi x)
        </me>.
    </p>

    <p>
      Weierstrass showed that if <m>a</m> is an odd integer,
      <m>b\in(0,1)</m>, and <m>ab>1+\frac{3}{2}\pi</m>, then <m>f</m>
      is continuous everywhere, but is nowhere differentiable.  Such a
      function is somewhat <q>fractal</q> in nature, and it is clear
      that a definition of continuity relying on intuition is
      inadequate to study it.
    </p>

    <problem>
      <idx><h>Weierstrass, Karl</h><h>continuous, everywhere non-differentiable function</h></idx>
      <idx><h>continuity</h><h>Weierstrass's continuous, but non-differentiable function</h></idx>
      <task>
        <statement>
          <p>
            Given
            <m>f(x)=\sum_{n=0}^\infty\left(\frac{1}{2}\right)^n\cos\left(a^n\pi
            x\right)</m>, what is the smallest value of <m>a</m> for
            which <m>f</m> satisfies Weierstrass' criterion to be
            continuous and nowhere differentiable.
          </p>
        </statement>
      </task>
      <task>
        <statement>
          <p>
            Let
            <m>f(x,N)=\sum_{n=0}^N\left(\frac{1}{2}\right)^n\cos\left(13^n\pi
            x\right)</m> and use a computer algebra system to plot
            <m>f(x,N)</m> for <m>N=0,1,2,3,4,10</m> and
            <m>x\in[0,1]</m>.
          </p>
        </statement>
      </task>
      <task>
        <statement>
          <p>
            Plot <m>f(x,10)</m> for <m>x\in[\,0,c]</m>, where
            <m>c=0.1,0.01,0.001,0.0001,0.00001</m>.  Based upon what
            you see in parts b and c, why would we describe the
            function to be somewhat <q>fractal</q> in nature?
          </p>
        </statement>
      </task>
    </problem>

    <p>
      Just as it was important to define convergence with a rigorous
      definition without appealing to intuition or geometric
      representations, it is imperative that we define continuity in a
      rigorous fashion not relying on graphs.
    </p>

    <p>
      The first appearance of a definition of continuity which did not
      rely on geometry or intuition was given in 1817 by Bernhard
      Bolzano <idx><h>Bolzano, Bernhard</h></idx> in a paper published
      in the Proceedings of the Prague Scientific Society entitled
      <foreign>Rein analytischer Beweis des Lehrsatzes dass zwieschen
      je zwey Werthen, die ein entgegengesetztes Resultat gewaehren,
      wenigstens eine reele Wurzel der Gleichung liege</foreign>
      (Purely Analytic Proof of the Theorem that Between Any Two
      Values that Yield Results of Opposite Sign There Will be at
      Least One Real Root of the Equation).
    </p>


    <figure>
      <caption><url href="https://mathshistory.st-andrews.ac.uk/Biographies/Bolzano/" visual="mathshistory.st-andrews.ac.uk/Biographies/Bolzano/">Bernhard Bolzano</url>(1781<ndash/>1848)
      </caption>

      <idx><h>Bolzano, Bernhard</h><h>portrait of</h></idx>
      <idx><h>Portraits</h><h>Bolzano</h></idx>

      <image width="35%" source="images/Bolzano.png" >
        <shortdescription>Portrait of Bernhard Bolzano</shortdescription>
      </image>
    </figure>

    <p>
      From the title it should be clear that in this paper Bolzano is
      proving the <xref ref="IntermediateValueTheorem"
      text="custom">Intermediate Value Theorem</xref>.  To do this he
      needs a completely analytic definition of continuity.  The
      substance of Bolzano's idea is that if <m>f</m> is continuous at
      a point <m>a</m> then <m>f(x)</m> should be <q>close to</q>
      <m>f(a)</m> whenever <m>x</m> is <q>close enough to</q>
      <m>a</m>.  More precisely, Bolzano said that <m>f</m> is
      continuous at <m>a</m> provided <m>\abs{f(x)-f(a)}</m> can be
      made smaller than any given quantity provided we make
      <m>\abs{x-a}</m> sufficiently small.
    </p>

    <p>
      The language Bolzano uses is very similar to the language
      Leibniz <idx><h>Leibniz, Gottfried Wilhelm</h></idx> used when
      he postulated the existence of infinitesimally small numbers.
      Leibniz said that infinitesimals are <q>smaller than any given
      quantity but not zero.</q> Bolzano says that
      <q><m>\abs{f(x)-f(a)}</m> can be made smaller than any given
      quantity provided we make <m>\abs{x-a}</m> sufficiently
      small.</q> But Bolzano stops short of saying that
      <m>\abs{x-a}</m> is <em>infinitesimally</em> small. He says that
      given <m>a</m>, we can choose <m>x</m> so that <m>\abs{x-a}</m>
      is smaller than any real number we could name, say <m>b</m>,
      provided we name <m>b</m> <em>first</em>. But for any given
      choice of <m>x</m>, <m>\abs{x-a}</m>, and <m>b</m> are both
      still real numbers.  Possibly very small real numbers to be
      sure, but real numbers nonetheless.  Infinitesimals have no
      place in Bolzano's construction.
    </p>

    <p>
      <idx><h>Bolzano, Bernhard</h></idx>
      Bolzano's paper was not well known when Cauchy <idx><h>Cauchy,
      Augustin</h></idx> proposed a similar definition in his
      <em>Cours d'analyse</em><nbsp /><xref
      ref="bradley09__cauch_cours" /> of 1821 so it is usually Cauchy
      who is credited with this definition, but even Cauchy's
      definition is not quite tight enough for modern standards.  It
      was Karl Weierstrass in 1859 who finally gave the modern
      definition.
    </p>

    <definition xml:id="def_continuity">
      
      <title>Continuity at a Point</title>

      <statement>
        <p>
          <idx><h>continuity</h><h>at a point</h></idx>
          <idx><h>Definition</h><h>continuity</h><h>at a point</h></idx> 

          We say that a function <m>\boldsymbol{f}</m> is continuous
          at <m>\boldsymbol{a}</m> provided that for any
          <m>\eps>0</m>, there exists a <m>\delta>0</m> such that if
          <m>\abs{x-a}\lt \delta</m> then <m>|f(x)-f(a)|\lt \eps</m>.
        </p>
      </statement>
    </definition>

    <p>
      Notice that the definition of continuity of a function is done
      point-by-point.  A function can certainly be continuous at some
      points while discontinuous at others.  When we say that <m>f</m>
      is continuous on an interval, then we mean that it is continuous
      at every point of that interval and, in theory, we would need to
      use the above definition to check continuity at each individual
      point.
    </p>

    <p>
      <idx><h>Extreme Value Theorem (EVT)</h><h>continuity and</h></idx>
      <idx><h>continuity</h><h>Extreme Value Theorem (EVT) and</h></idx> 
      <idx><h>Intermediate Value Theorem (IVT)</h><h>continuity and</h></idx>
      <idx><h>continuity</h><h>Intermediate Value Theorem and</h></idx>

      Our definition fits the bill in that it does not rely on either
      intuition or graphs, but it is this very non-intuitiveness that
      makes it hard to grasp.  It usually takes some time to become
      comfortable with this definition, let alone use it to prove
      theorems such as the <xref ref="thm_EVT" text="custom">Extreme
      Value Theorem</xref> and <xref ref="IntermediateValueTheorem"
      text="custom">Intermediate Value Theorem</xref>.  So let's go
      slowly to develop a feel for it.
    </p>

    <p>
      This definition spells out a completely black and white
      procedure: you give me a positive number <m>\eps</m>, and I must
      be able to find a positive number <m>\delta</m> which satisfies
      a certain property.  If I can always do that then the function
      is continuous at the point of interest.
    </p>

    <p> 
      This definition also makes very precise what we mean when we say
      that <m>f(x)</m> should be <q>close to</q> <m>f(a)</m> whenever
      <m>x</m> is <q>close enough to</q> <m>a</m>.  For example,
      intuitively we know that <m>f(x)=x^2</m> should be continuous at
      <m>x=2</m>.  This means that we should be able to get <m>x^2</m>
      to within, say, <m>\eps=0.1</m> of <m>4</m> provided we make
      <m>x</m> close enough to <m>2</m>.  Specifically, we want
      <m>3.9\lt x^2\lt 4.1</m>.  This happens exactly when
      <m>\sqrt{3.9}\lt x\lt \sqrt{4.1}</m>.  Using the fact that
      <m>\sqrt{3.9}\lt 1.98</m> and <m>2.02\lt \sqrt{4.1}</m>, then we
      can see that if we get <m>x</m> to within <m>\delta=.02</m> of
      <m>2</m>, then <m>\sqrt{3.9}\lt 1.98\lt x\lt 2.02\lt
      \sqrt{4.1}</m> and so <m>x^2</m> will be within .<m>1</m> of
      <m>\,4</m>.  This is very straightforward.  What makes this
      situation more difficult is that we must be able to do this for
      any <m>\eps>0</m>.
    </p>

    <p>
      Notice the similarity between this definition and the definition
      of convergence of a sequence.  Both definitions have the
      challenge of an <m>\eps>0</m>.  In the definition of
      <m>\limit{n}{\infty}{s_n}=s</m>, we had to get <m>s_n</m>
      to within <m>\eps</m> of <m>s</m> by making <m>n</m> large
      enough.  For sequences, the challenge lies in making
      <m>\abs{s_n-s}</m> sufficiently small.  More precisely, given
      <m>\eps>0</m> we need to decide how large <m>n</m> should be to
      guarantee that <m>\abs{s_n-s}\lt \eps</m>.
    </p>

    <p>
      In our definition of continuity, we still need to make something
      small (namely <m>\abs{f(x)-f(a)}\lt \eps</m>), only this time,
      we need to determine how close <m>x</m> must be to <m>a</m> to
      ensure this will happen instead of determining how large
      <m>n</m> must be.
    </p>

    <p>
      What makes <m>f</m> continuous at <m>a</m> is the arbitrary
      nature of <m>\eps</m> (as long as it is positive).  As
      <m>\eps</m> becomes smaller, this forces <m>f(x)</m> to be
      closer to <m>f(a)</m>.  That we can always find a positive
      distance <m>\delta</m> to work is what we mean when we say that
      we can make <m>f(x)</m> as close to <m>f(a)</m> as we wish,
      provided we get <m>x</m> close enough to <m>a</m>.  The sequence
      of pictures below illustrates that the phrase <q>for any
      <m>\eps>0</m>, there exists a <m>\delta>0</m> such that if
      <m>|\,x-a|\lt \delta</m> then <m>|f(x)-f(a)|\lt \eps</m></q> can
      be replaced by the equivalent formulation <q>for any
      <m>\eps>0</m>, there exists a <m>\delta>0</m> such that if
      <m>a-\delta\lt x\lt a+\delta</m> then <m>f(a)-\eps\lt f(x)\lt
      f(a)+\eps</m>.</q> This could also be replaced by the phrase
      <q>for any <m>\eps>0</m>, there exists a <m>\delta>0</m> such
      that if <m>x\in(a-\delta,a+\delta)</m> then
      <m>f(x)\in(f(a)-\eps,f(a)+\eps)</m>.</q> All of these equivalent
      formulations convey the idea that we can get <m>f(x)</m> to
      within <m>\eps</m> of <m>f(a)</m>, provided we make <m>x</m>
      within <m>\delta</m> of <m>a</m>, and we will use whichever
      formulation suits our needs in a particular application.
    </p>

    <!-- <aside> -->
    <!--   <title>Note to self</title> -->
    <!--   <p> -->
    <!--     This figure should be animated.  -->
    <!--   </p> -->
    <!-- </aside> -->


    <sbsgroup widths="45% 45%" margins="auto" valign="middle">
      <sidebyside>
        <image width="37%" source="images/Ch5fig3a.png" />
        <image width="37%" source="images/Ch5fig3b.png" />
      </sidebyside>
      <sidebyside>
        <image width="37%" source="images/Ch5fig3c.png" />
        <image width="37%" source="images/Ch5fig3d.png" />
      </sidebyside>
    </sbsgroup>


    <p>
      The precision of the definition is what allows us to examine
      continuity without relying on pictures or vague notions such as
      <q>nearness</q> or <q>getting closer to.</q> We will now
      consider some examples to illustrate this precision.
    </p>

    <example>
      <statement>
        <p>
          Use the definition of continuity to show that <m>f(x)=x</m>
          is continuous at any point <m>a</m>.
        </p>
      </statement>
    </example>

    <p>
      If we were to draw the graph of this function, then you would likely
      say that this is obvious.  The point behind the definition is
      that we can back up your intuition in a rigorous manner.
    </p>

    <proof>
      <p>
        Let <m>\eps>0</m>.
        Let <m>\delta=\eps</m>.
        If <m>|\,x-a|\lt \delta</m>, then
        <me>
          |f(x)-f(a)|=|\,x-a|\lt \eps
        </me>
      </p>
      <aside>
        
        <p>
          Take particular note in these proofs that our choice of
          <m>\delta</m> guarantees that <m>\delta\gt0</m>. This is
          obvious now. But as things become more complicated <mdash/>
          for example, see <xref ref="prob_Cauchy_s_incorrect_proof"
          ></xref> <mdash/> it will be easy to chose a <m>\delta</m>
          that could be equal to zero which will invalidate the proof.
        </p>
        <p>
          Also, the goal is to write clearly and concisely, but it is better
          to be clear and a little verbose than to be so concise that
          your meaning is hidden. So when writing proofs this
          delicate it is important to take great care to be very
          clear.  If there is any possible ambiguity it is better to
          state explicitly that, for example, <q><m>\delta \gt
          0</m></q>, rather than leaving it to the reader to figure
          out.
        </p>

      </aside>

      <p>
        Thus by the definition, <m>f</m> is continuous at <m>a</m>.
      </p>
    </proof>

    <problem>
      <statement>
        <p>
          <idx><h>continuity</h><h><m>f(x) = mx +b</m> is continuous everywhere</h></idx> 
          Use the definition of continuity to show that if <m>m</m>
          and <m>b</m> are fixed (but unspecified) real numbers then
          the function
          <me>
            f(x) = mx+b
          </me>
          is continuous at every real number <m>a</m>.
        </p>
      </statement>
    </problem>

    <example>
      <statement>
        <p>
          Use the definition of continuity to show that
          <m>f(x)=x^2</m> is continuous at <m>a=0</m>.
        </p>
      </statement>
    </example>

    <proof>
      <p>
        Let <m>\eps>0</m>.
        Let <m>\delta=\sqrt{\eps}</m>.
        If <m>|\,x-0|\lt \delta</m>, then <m>|\,x|\lt \sqrt{\eps}</m>.
        Thus
        <me>
          \abs{x^2-0^2}=|\,x|^2\lt \left(\sqrt{\eps}\right)^2=\eps
          </me>.
      </p>

      <p>
        Thus by the definition, <m>f</m> is continuous at <m>0</m>.
      </p>
    </proof>

    <p>
      Notice that in these proofs, the challenge of an <m>\eps>0</m>
      was given first.  This is because the choice of <m>\delta</m>
      must depend upon <m>\eps</m>.  Also notice that there was no
      explanation for our choice of <m>\delta</m>.  We just supplied
      it and showed that it worked.  As long as <m>\delta>0</m>, then
      this is all that is required.  In point of fact, the
      <m>\delta</m> we chose in each example was not the only choice
      that worked; any smaller <m>\delta</m> would work as well.
    </p>

    <problem>
      <idx><h>continuity</h><h>smaller <m>\delta</m>, bigger <m>\eps</m></h></idx>
      <idx><h>continuity</h><h>smaller <m>\delta</m> works in definition</h></idx>
      <idx><h>continuity</h><h>larger <m>\eps</m> works in definition</h></idx>
      <task>
        <statement>
          <p>
            Given a particular <m>\eps>0</m> in the definition of
            continuity, show that if a particular <m>\delta_0>0</m>
            satisfies the definition, then any <m>\delta</m> with
            <m>0\lt \delta\lt \delta_0</m> will also work for this
            <m>\eps</m>.
          </p>
        </statement>
      </task>
      <task>
        <statement>
          <p>
            Show that if a <m>\delta</m> can be found to satisfy the
            conditions of the definition of continuity for a
            particular <m>\eps_0>0</m>, then this <m>\delta</m> will
            also work for any <m>\,\eps</m> with <m>0\lt \eps_0\lt
            \eps</m>.
          </p>
        </statement>
      </task>
    </problem>

    <p>
      It wasn't explicitly stated in the definition but when we say
      <q>if <m>\abs{x-a}\lt \delta</m> then <m>|f(x)-f(a)|\lt
      \eps</m>,</q> we should be restricting ourselves to <m>x</m>
      values which are in the domain of the function <m>f</m>,
      otherwise <m>f(x)</m> doesn't make sense.  We didn't put it in
      the definition because that definition was complicated enough
      without this technicality.  Also in the above examples, the
      functions were defined everywhere so it was a moot point.  We
      will continue with the convention that when we say <q>if
      <m>|\,x-a|\lt \delta</m> then <m>|f(x)-f(a)|\lt \eps</m>,</q> we
      will be restricting ourselves to <m>x</m> values which are in
      the domain of the function <m>f</m>.  This will allow us to
      examine continuity of functions not defined for all <m>x</m>
      without restating this restriction each time.
    </p>

    <problem xml:id="prob_extended_sqrt_is_continuous_at_zero">
      <statement>
        <p>
          <idx><h>continuity</h><h><m>\pm\sqrt{x}</m> is continuous at zero</h></idx>
          Use the definition of continuity to show that
          <me>
            f(x)= \begin{cases}\sqrt{x} \amp  \text{ if }  x\ge0\\ -\sqrt{-x} \amp  \text{ if }  x\lt 0 \end{cases}
          </me>
          is continuous at <m>a=0</m>.
        </p>
      </statement>
    </problem>

    <problem>
      <statement>
        <p>
          <idx><h><m>\sqrt{x}</m></h><h>is continuous at zero</h></idx> 
          Use the definition of continuity to show that <m>f(x)=
          \sqrt{x}</m> is continuous at <m>a=0</m>.  How is this
          problem different from <xref
          ref="prob_extended_sqrt_is_continuous_at_zero"></xref>?
          How is it similar?
        </p>
      </statement>
    </problem>

    <p>
      Sometimes the <m>\delta</m> that will work for a particular
      <m>\eps</m> is fairly obvious to see, especially after you've
      gained some experience.  This is the case in the above examples
      (at least after looking back at the proofs).  However, finding
      <m>\delta</m> is usually not so obvious and requires some
      scrapwork.  This scrapwork is vital toward producing a
      <m>\delta</m>, but again is not part of the polished proof.
      This can be seen in the following example.
    </p>

    <example xml:id="example_SqrtContinuous">
      <statement>
        <p>
          Use the definition of continuity to prove that
          <m>f(x)=\sqrt{x}</m> is continuous at <m>a=1</m>.
        </p>

        <p>
          <term>SCRAPWORK</term>
        </p>
        <p>
          As before, the scrapwork for these problems often consists of
          simply working backwards.  Specifically, given an <m>\eps>0</m>,
          we need to find a <m>\delta>0</m> so that
          <m>\abs{\sqrt{x}-\sqrt{1}}\lt \eps</m>, whenever <m>\abs{x-1}\lt
          \delta</m>.  We work backwards from what we want, keeping an eye
          on the fact that we can control the size of <m>\abs{x-1}</m>.
          <me>
            \abs{\sqrt{x}-\sqrt{1}}=\abs{\frac{\left(\sqrt{x}-1\right)\left(\sqrt{x}+1\right)}{\sqrt{x}+1}|}=\frac{\abs{x-1}}{\sqrt{x}+1}\lt
            \abs{x-1}
            </me>.
        </p>

        <p>
          This seems to suggest that we should make <m>\delta=\eps</m>.
          We're now ready for the formal proof.
        </p>
      </statement>
    </example>


    <proof>
      <p>
        Let <m>\eps>0</m>.
        Let <m>\delta=\eps</m>.
        If <m>\abs{x-1}\lt \delta</m>, then <m>\abs{x-1}\lt \eps</m>, and so
        <me>
          \abs{\sqrt{x}-\sqrt{1}}=\abs{\frac{\left(\sqrt{x}-1\right)\left(\sqrt{x}+1\right)}{ \sqrt{x}+1}}=\frac{\abs{x-1}}{\sqrt{x}+1}\lt \abs{x-1}\lt \eps
          </me>.
      </p>

      <p>
        Thus by definition, <m>f(x)=\sqrt{x}</m> is continuous at <m>1</m>.
      </p>
    </proof>



    <p>
      Bear in mind that someone reading the formal proof will not have
      seen the scrapwork, so the choice of <m>\delta</m> might seem
      rather mysterious.  However, you are in no way bound to motivate
      this choice of <m>\delta</m> and usually you should not, unless
      it is necessary for the formal proof.  All you have to do is
      find this <m>\delta</m> and show that it works.   To
      a trained reader, your ideas will come through when you
      demonstrate that your choice of <m>\delta</m> works.
    </p>
    <figure>
      <caption><url href="https://mathshistory.st-andrews.ac.uk/Biographies/Halmos/" visual="mathshistory.st-andrews.ac.uk/Biographies/Halmos/">Paul Halmos</url></caption>

      <idx><h>Halmos, Paul</h><h>portrait of</h></idx>
      <idx><h>Portraits</h><h>Halmos</h></idx>

      <image width="35%" source="images/Halmos.png" >
        <shortdescription>Portrait of Paul Halmos</shortdescription>
      </image>
    </figure>
    <p>
      Now reverse this last statement.  <em>As</em> a trained reader,
      when you read the proof of a theorem it is <em>your</em>
      responsibility to find the scrapwork, to see how the proof works
      and understand it fully.  As the renowned mathematical expositor
      Paul Halmos <idx><h>Halmos, Paul</h></idx> (1916-2006) said,
    </p>

    <blockquote>
      <p>
        <q>
          Don't just read it; fight it! Ask your own questions, look for
          your own examples, discover your own proofs. Is the hypothesis
          necessary? Is the converse true? What happens in the classical
          special case? What about the degenerate cases? Where does the
          proof use the hypothesis?
        </q>
      </p>

    </blockquote>


<p>
  This is the way to learn mathematics.  It is really the only
  way.
</p>

<problem>
  <idx><h><m>\sqrt{x}</m></h><h>is continuous at every positive real number</h></idx>
  <statement>
    <p>
      Use the definition of continuity to show that
      <m>f(x)=\sqrt{x}</m> is continuous at any positive real
      number <m>a</m>.
    </p>
  </statement>
</problem>

<problem>
  <idx><h><m>\sin x</m></h><h>is continuous for <m>0\leq x\lt \frac{\pi}{2}</m></h></idx>
  <task>
    <statement>
      <p>
        Use a unit circle to show that for <m>0\leq\theta\lt
        \frac{\pi}{2}</m>, <m>\sin \theta\leq\theta</m> and
        <m>1-\cos \theta\leq\theta</m> and conclude <m>\abs{\sin
        \theta}\leq\abs{\theta}</m> and <m>\abs{1-\cos
        \theta}\leq\abs{\theta}</m> for <m>-\frac{\pi}{2}\lt
        \theta</m> <m>\lt \frac{\pi}{2}</m>.
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>
        Use the definition of continuity to prove that
        <m>f(x)=\sin x</m> is continuous at any point <m>a</m>.
      </p>
    </statement>
    <hint>
      <p>
        <m>\sin x=\sin\left(x-a+a\right)</m>.
      </p>
    </hint>
  </task>
</problem>


<problem>
  <idx><h>continuity</h><h><m>e^x</m> is continuous everywhere</h></idx>
  <idx><h>continuous functions</h><h><m>e^x</m> is continuous everywhere</h></idx>
  <task>
    <statement>
      <p>
        Use the definition of continuity to show that
        <m>f(x)=e^x</m> is continuous at <m>a=0</m>.
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>
        Show that <m>f(x)=e^x</m> is continuous at any point <m>a</m>.  
      </p>
    </statement>
    <hint>
      <p>
        Rewrite <m>e^x-e^a</m> as
        <m>e^{a+(x-a)}-e^a</m> and use what you proved in part a.
      </p>
    </hint>
  </task>
</problem>

<p>
  In the above problems, we used the definition of continuity
  to verify our intuition about the continuity of familiar
  functions.  The advantage of this analytic definition is
  that it can be applied when the function is not so
  intuitive.  Consider, for example, the function given at the
  end of the last chapter.
  <me> f(x)= \begin{cases}
  x\,\sin\left(\frac{1}{x}\right),\amp \text{ if } x\neq 0\\
  0, \amp \text{ if } x=0 
  \end{cases}  </me>.
</p>

<p>
  Near zero, the graph of <m>f(x)</m> looks like this:
</p>
<image width="75%" source="images/Ch5fig4.png" >
  <shortdescription></shortdescription>
</image>

<p>
  As we mentioned in the previous chapter, since
  sin<m>\left(\frac{1}{x}\right)</m> oscillates infinitely
  often as <m>x</m> nears zero this graph must be viewed with
  a certain amount of suspicion.  However our completely
  analytic definition of continuity shows that this function
  is, in fact, continuous at 0.
</p>

<problem>
  <statement>
    <p>
      <idx><h>Topologist's sine function</h><h>is continuous at zero</h></idx>
      Use the definition of continuity to show that
      <me>
        f(x)= \begin{cases}
        x\,\sin\left(\frac{1}{x}\right),\amp \text{ if } x\neq 0\\ 
        0, \amp \text{ if } x=0 
        \end{cases}
      </me>
      is continuous at <m>0</m>.
    </p>
  </statement>
</problem>

<p>
  Even more perplexing is the function defined by
  <me>
    D(x)=
    \left\{ 
    \begin{matrix}
    x\text{,} \amp \text{ if } x\text{ is rational } \\
    0\text{,} \amp \text{ if } x\text{ is irrational. } 
    \end{matrix}
    \right.
  </me>
  <!-- <me>      -->
  <!--         D(x)= \begin{cases} -->
  <!--               x, \amp \text{ if } x \text{ is rational } \\ -->
  <!--               0, \amp \text{ if } x \text{ is irrational.} -->
  <!--                \end{cases} -->
  <!--       </me> -->
</p>

<p>
  To the naked eye, the graph of this function looks like the
  lines <m>y=0</m> and <m>y=x</m>.  Of course, such a graph would
  not be the graph of a function.  Actually, both of these lines
  have holes in them.  Wherever there is a point on one line there
  is a <q>hole</q> on the other.  Each of these holes is the
  width of a single point (that is, their <q>width</q> is zero!)
  so they are invisible to the naked eye (or even magnified under
  the most powerful microscope available).  This idea is
  illustrated in the following graph
</p>
<image width="60%" source="images/Ch5fig5.png" >
  <shortdescription></shortdescription>
</image>
<p>
  Can such a function so <q>full of holes</q> actually be
  continuous anywhere?  It turns out that we can use our
  definition to show that this function is, in fact, continuous at
  <m>0</m> and at no other point.
</p>

<problem>
  <idx><h>continuity</h><h>of <m> D(x)= \begin{cases}x,\amp    \text{ if } x\text{ is rational } \\ 0,\amp \text{ if } x\text{ is irrational } \end{cases} </m></h></idx>
  <task>
    <statement>
      <p>
        Use the definition of continuity to show that the
        function
        <me> D(x)= \begin{cases}
        x,\amp \text{ if } x\text{ is rational } \\
        0,\amp \text{ if } x\text{ is irrational } \end{cases} </me>
        is continuous at <m>0</m>.
      </p>
    </statement>
  </task>
  <task>
    <statement>
      <p>
        Let <m>a\neq 0</m>.  Use the definition of continuity to
        show that <m>D</m> is not continuous at <m>a</m>.
      </p>
    </statement>
    <hint>
      <p>
        You might want to break this up into two cases where
        <m>a</m> is rational or irrational.  Show that no choice
        of <m>\delta>0</m> will work for <m>\eps=\abs{a}</m>.  Note
        that <xref
        ref="thm_IrrationalBetweenIrrationals"></xref> of
        <xref ref="NumbersRealRational"></xref> will
        probably help here.
      </p>
    </hint>
  </task>
</problem>
<problem>
  <idx><h>continuous functions</h><h>a constant function is continuous</h></idx>

  <statement>
    <p>
      Use the definition of continuity to prove that the constant
      function <m>g(x)=c</m> is continuous at any point <m>a</m>.
    </p>
  </statement>
</problem>

<problem>
  <idx><h>continuous functions</h><h><m>\ln x</m> is continuous everywhere</h></idx>
  <task>
    <statement>
      <p>
        Use the definition of continuity to prove that <m>\ln x</m>
        is continuous at <m>1</m>.
      </p>
    </statement>
    <hint>
      <p>
        You may want to use the fact <m>\abs{\ln x}\lt
        \eps\,\Leftrightarrow-\eps\lt \ln x\lt \eps</m> to find a
        <m>\delta</m>.
      </p>
    </hint>
  </task>
  <task>
    <statement>
      <p>
        Use part (a) to prove that <m>\ln x</m> is continuous at any
        positive real number <m>a</m>.
      </p>
    </statement>
    <hint>
      <p>
        <m>\ln(x)=\ln(x/a)+\ln(a)</m>.  This is a combination of functions
        which are continuous at <m>a</m>.  Be sure to explain how you know
        that <m>\ln(x/a)</m> is continuous at <m>a</m>.
      </p>
    </hint>
  </task>
</problem>

<problem>
  <statement>
    <p>
      <idx><h>continuity</h><h>formal definition of discontinuity</h></idx>

      Write a formal definition of the statement <m>f</m> is not continuous
      at <m>a</m>, and use it to prove that the function
      <me>
        f(x)= 
        \begin{cases}
        x\amp \text{ if } x\neq 1\\
        0\amp \text{if } x=1 
        \end{cases}
      </me>
      is not continuous at <m>a=1</m>.
    </p>
  </statement>
</problem>
</section>

  <section xml:id="SequencesAndContinuity">
    <title>Sequences and Continuity</title>
    <p>
      There is an alternative way to prove that the function
      <me>
        D(x)=\left\{ \begin{matrix}x\text{,} \amp \text{ if } x\text{ is rational } \\ 0\text{,} \amp \text{ if } x\text{ is irrational } \end{matrix} \right.
      </me>
      is not continuous at <m>a\neq 0</m>.  We will examine this
      by looking at the relationship between our definitions of
      convergence and continuity.  The two ideas are actually
      quite closely connected, as illustrated by the following
      very useful theorem.
    </p>

    <theorem xml:id="thm_LimDefOfContinuity">
      <statement>
        <p>
          <idx><h>continuity</h><h>via limits</h></idx>
          The function <m>f</m> is continuous at <m>a</m> if and only
          if <m>f</m> satisfies the following property:
          <me>
            \forall\text{ sequences } \left(x_n\right)\text{,  if }
            \,\,\limit{n}{\infty}{x_n}=a \text{ then} \limit{n}{\infty}{f(x_n)}=f(a).
          </me>
        </p>
      </statement>
    </theorem>

    <p>
      <xref ref="thm_LimDefOfContinuity"></xref> says that
      in order for <m>f</m> to be continuous, it is necessary and
      sufficient that any sequence <m>\left(x_n\right)</m>
      converging to <m>a</m> must force the sequence
      <m>\left(f(x_n)\right)</m> to converge to <m>f(a)</m>.  A
      picture of this situation is below though, as always, the
      formal proof will not rely on the diagram.
    </p>
    <!-- <aside> -->
    <!--   <title>Note to self</title> -->
    <!--   <p> -->
    <!--     This figure should be animated.  -->
    <!--   </p> -->
    <!-- </aside> -->

    <image width="37%" source="images/Ch5fig6.png" >
      <shortdescription></shortdescription>
    </image>


    <p>
      This theorem is especially useful for showing that a function
      <m>f,</m> is not continuous at a point <m>a</m>; all we need to
      do is exhibit a sequence <m>\left(x_n\right)</m> converging to
      <m>a</m> such that the sequence
      <m>\limit{n}{\infty}{f(x_n)}</m> does <em>not</em>
      converge to <m>f(a)</m>.  Let's demonstrate this idea before we
      tackle the proof of <xref
      ref="thm_LimDefOfContinuity"></xref>.
    </p>

    <example xml:id="example_HeavisideNotContinuous">
      <statement>
        <p>
          Use <xref ref="thm_LimDefOfContinuity"></xref> to prove that
          <me>
            f(x)= \begin{cases}\frac{|x|}{x}\text{,} \amp \text{ if } x\neq 0\\ 0\text{,} \amp \text{ if } x=0 \end{cases}
          </me>
          is not continuous at <m>0</m>.
        </p>
      </statement>
    </example>
    <proof>
      <p>
        First notice that <m>f</m> can be written as
        <me>
          f(x)= \begin{cases}1\amp \text{ if } x>0\\ -1\amp \text{ if } x\lt 0\\ 0\amp \text{ if } x=0 \end{cases} 
          </me>.
      </p>

      <p>
        To show that <m>f</m> is not continuous at <m>0</m>, all
        we need to do is create a single sequence 
        <m>\left(x_n\right)</m> which converges to <m>0</m>, but
        for which the sequence
        <m>\left(f\left(x_n\right)\right)</m> does not converge to
        <m>f(0)=0</m>.  For a function like this one, just about
        any sequence will do, but let's use
        <m>\left(\frac{1}{n}\right)</m>, just because it is an old
        familiar friend.
      </p>

      <p>
        We have <m>\limit{n}{\infty}{\frac{1}{n}}=0</m>, but
        <m>\limit{n}{\infty}{f\left(\frac{1}{n}\right)}=\limit{n}{
        \infty}{1}=1\neq 0=f(0)</m>.  Thus by <xref
        ref="thm_LimDefOfContinuity"></xref>, <m>f</m> is not
        continuous at <m>0</m>.
      </p>
    </proof>


    <problem>
      <statement>
        <p>
          <idx><h>continuity</h><h>Heaviside's function is not continuous at zero</h></idx> 
          Use <xref ref="thm_LimDefOfContinuity"></xref> to
          show that
          <me>
            f(x)= \begin{cases}
            \frac{\abs{x}}{x},\amp \text{ if } x\neq 0\\
          a, \amp \text{ if } x=0 \end{cases}  </me>
          is not continuous at <m>0</m>, no matter what value <m>a</m>
          is.
        </p>
      </statement>
    </problem>

    <problem>
      <idx><h>continuity</h><h>of <m> D(x)= \begin{cases}x,\amp \text{ if } x\text{ is rational } \\ 0,\amp \text{ if } x\text{ is irrational } \end{cases} </m></h></idx>
      <statement>
        <p>
          Use <xref ref="thm_LimDefOfContinuity"></xref> to show that
          <me>
            D(x)= \begin{cases}
            x, \amp \text{ if } x\text{ is rational } \\
          0, \amp \text{ if } x\text{ is irrational } \end{cases}  </me>
          is not continuous at <m>a\neq 0</m>.
        </p>
      </statement>
    </problem>

    <problem>
      <title>Topologist's Sine Curve</title>
      <idx><h>Topologist's sine function</h><h>modified version is not continuous at zero</h></idx>
      <statement>
        <p>
          The function <m>T(x)=\sin\left(\frac{1}{x}\right)</m> is
          often called the topologist's sine curve.  Whereas <m>\sin
          x</m> has roots at <m>n\pi</m>, <m>n\in\ZZ</m> and
          oscillates infinitely often as <m>x\rightarrow\pm\infty</m>,
          <m>T</m> has roots at <m>\frac{1}{n\pi},\,n\in\ZZ,\,n\neq
          0</m>, and oscillates infinitely often as <m>x</m>
          approaches zero.  A rendition of the graph follows.
        </p>
        <image width="75%" source="images/Ch5fig7.png" >
          <shortdescription></shortdescription>
        </image>

        <p>
          Notice that <m>T</m> is not even defined at <m>x=0</m>.
          We can extend <m>T</m> to be defined at 0 by simply
          choosing a value for <m>T(0):</m>
          <me>
            T(x)= \begin{cases}
            \sin\left(\frac{1}{x}\right),\amp \text{ if } x\neq 0\\ 
            b,\amp \text{ if } x=0 \end{cases} </me>.
        </p>

        <p>
          Use <xref ref="thm_LimDefOfContinuity"></xref>
          to show that <m>T</m> is not continuous at <m>0</m>,
          no matter what value is chosen for <m>b</m>.
        </p>
      </statement>
    </problem>

    <proof>
      <title>Sketch of the Proof of <xref ref="thm_LimDefOfContinuity"></xref></title>
      <p>
        We've seen how we can use <xref
        ref="thm_LimDefOfContinuity"></xref>, now we need to
        prove <xref ref="thm_LimDefOfContinuity"></xref>.  The
        forward direction is fairly straightforward.  So we assume
        that <m>f</m> is continuous at <m>a</m> and start with a
        sequence <m>\left(x_n\right)</m> which converges to <m>a</m>.
        What is left to show is that
        <m>\limit{n}{\infty}{f(x_n)}=f(a)</m>.  If you write
        down the definitions of <m>f</m> being continuous at <m>a</m>,
        <m>\limit{n}{\infty}{x_n}=a</m>, and
        <m>\limit{n}{\infty}{f(x_n)}=f(a)</m>, you should be
        able to get from what you are assuming to what you want to
        conclude.
      </p>

      <p>
        To prove the converse, it is convenient to prove its
        contrapositive.  That is, we want to prove that if <m>f</m> is
        not continuous at <m>a</m> then we can construct a sequence
        <m>\left(x_n\right)</m> that converges to <m>a</m> but
        <m>\left(f(x_n)\right)</m>does not converge to <m>f(a)</m>.
        First we need to recognize what it means for <m>f</m> to not
        be continuous at <m>a</m>.  This says that somewhere there
        exists an <m>\eps>0</m>, such that no choice of
        <m>\delta>0</m> will work for this.  That is, for any such
        <m>\delta</m>, there will exist <m>x</m>, such that
        <m>|\,x-a|\lt \delta</m>, but <m>|f(x)-f(a)|\geq\eps</m>.
        With this in mind, if <m>\delta=1</m>, then there will exist
        an <m>x_1</m> such that <m>|\,x_1-a|\lt 1</m>, but
        <m>|f(x_1)-f(a)|\geq\eps</m>.  Similarly, if
        <m>\delta=\frac{1}{2}</m>, then there will exist an <m>x_2</m>
        such that <m>|\,x_2-a|\lt \frac{1}{2}</m>, but
        <m>|\,f(x_2)-f(a)|\geq\eps</m>.  If we continue in this
        fashion, we will create a sequence <m>\left(x_n\right)</m>
        such that <m>|\,x_n-a|\lt \frac{1}{n}</m>, but
        <m>|f(x_n)-f(a)|\geq\eps</m>.  This should do the trick.
      </p>
    </proof>

    <problem>
      <statement>
        <p>
          <idx><h>continuity</h><h>via limits</h></idx>
          <idx><h>limit</h><h><m>\limit{x}{a}{f(x)}=f(a)</m> implies <m>f(x)</m> is continuous</h></idx>
          Turn the ideas of the previous two paragraphs into a formal proof of <xref ref="thm_LimDefOfContinuity"></xref>.
        </p>
      </statement>
    </problem>

    <p>
      <xref ref="thm_LimDefOfContinuity"></xref> is a very useful result.
      It is a bridge between the ideas of convergence and continuity so it allows us to bring all of the theory we developed in <xref ref="Convergence"></xref>
      to bear on continuity questions.
      For example consider the following.
    </p>

    <theorem xml:id="thm_ContSumProd">
      <statement>
        <p>
          <idx><h>continuous functions</h><h>sum of continuous functions is continuous</h></idx>
          Suppose <m>f</m> and <m>g</m> are both continuous at <m>a</m>.
          Then <m>f+g</m> and <m>f\cdot g</m> are continuous at <m>a</m>.
        </p>
      </statement>
    </theorem>

    <proof>
      <p>
        We could use the definition of continuity to prove <xref
        ref="thm_ContSumProd"></xref>, but <xref
        ref="thm_LimDefOfContinuity"></xref> makes our job much
        easier.  For example, to show that <m>f+g</m> is continuous,
        consider any sequence <m>\left(x_n\right)</m> which converges
        to <m>a</m>.  Since <m>f</m> is continuous at <m>a</m>, then
        by <xref ref="thm_LimDefOfContinuity"></xref>,
        <m>\limit{n}{\infty}{f(x_n)}=f(a)</m>.  Likewise, since
        <m>g</m> is continuous at <m>a</m>, then
        <m>\limit{n}{\infty}{g(x_n)}=g(a)</m>.  
      </p>
      <p>
        By <xref ref="thm_SumOfSequences"></xref> of <xref
        ref="Convergence"></xref>,<m></m>
        <md alignment="alignat">
          <mrow>\limit{n}{\infty}{(f+g)(x_n)}\amp=\limit{n}{\infty}{
            \left(f(x_n)+g(x_n)\right)}</mrow>
          <mrow>\amp
          =\limit{n}{\infty}{f(x_n)}+\limit{n}{\infty}{g(x_n)}</mrow>
          <mrow>\amp =f(a)+g(a)</mrow>
          <mrow>\amp =(f+g)(a).</mrow>
        </md>
        Thus by <xref ref="thm_LimDefOfContinuity"></xref>,
        <m>f+g</m> is continuous at <m>a</m>.  The proof that
        <m>f\cdot g</m> is continuous at <m>a</m> is similar.
      </p>
    </proof>

    <problem>
      <idx><h>continuous functions</h><h>the product of continuous
      functions is continuous</h></idx>

      <statement>
        <p>
          Use <xref ref="thm_LimDefOfContinuity"></xref> to
          show that if <m>f</m> and <m>g</m> are continuous at
          <m>a</m>, then <m>f\cdot g</m> is continuous at <m>a</m>.
        </p>
      </statement>
    </problem>

    <p>
      By employing <xref ref="thm_ContSumProd"></xref> a finite
      number of times, we can see that a finite sum of continuous
      functions is continuous.  That is, if
      <m>f_1,\,f_2,\,\ldots,\,f_n</m> are all continuous at <m>a</m>
      then <m>\sum_{j=1}^nf_j</m> is continuous at <m>a</m>.  But what
      about an infinite sum?  Specifically, suppose
      <m>f_1,\,f_2,f_3,\ldots</m> are all continuous at <m>a</m>.
      Consider the following argument.
    </p>

    <p>
      Let <m>\eps>0</m>.  Since <m>f_j</m> is continuous at <m>a</m>,
      then there exists <m>\delta_j>0</m> such that if <m>|\,x-a|\lt
      \delta_j</m>, then <m>|f_j(x)-f_j(a)|\lt \frac{\eps}{2^j}</m>.
      Let
      <m>\delta=</m>min<m>\left(\delta_1,\,\delta_2,\,\ldots\right)</m>.
      If <m>|\,x-a|\lt \delta</m>, then
      <me>
        \left|\sum_{j=1}^\infty f_j(x)-\sum_{j=1}^\infty f_j(a)\right|=\left|\sum_{j=1}^\infty\left(f_j(x)-f_j(a)\right)\right|
      </me>
      <me>
        \leq\,\sum_{j=1}^\infty|f_j(x)-f_j(a)|\lt \sum_{j=1}^\infty\frac{ \eps}{2^j}=\eps
        </me>.
    </p>

    <p>
      Thus by definition, <m>\sum_{j=1}^\infty f_j</m> is continuous
      at <m>a</m>.
    </p>

    <p>
      This argument seems to say that an infinite sum of continuous
      functions must be continuous (provided it converges).  However
      we know that the Fourier series
      <me>
        \frac{4}{\pi}\sum_{k=0}^\infty\frac{\left(-1\right)^k}{\left(2k+1\right)}\cos\left(\left(2k+1\right)\pi x\right)
      </me>
      is a counterexample to this, as it is an infinite sum of
      continuous functions which does not converge to a continuous
      function.  Something fundamental seems to have gone wrong here.
      Can you tell what it is?
    </p>

    <p>
      This is a question we will spend considerable time addressing in
      <xref ref="PowerSeriesRedux"></xref> (in particular, see
      <xref ref="prob_Cauchy_s_incorrect_proof"></xref>) so if
      you don't see the difficulty, don't worry; you will.  In the
      meantime keep this problem tucked away in your consciousness.
      It is, as we said, fundamental.
    </p>

    <p>
      <xref ref="thm_LimDefOfContinuity"></xref> will also
      handle quotients of continuous functions.  There is however a
      small detail that needs to be addressed first.  Obviously, when
      we consider the continuity of <m>f/g</m> at <m>a</m>,<m></m>we
      need to assume that <m>g(a)\neq 0</m>.  However, <m>g</m> may be
      zero at other values.  How do we know that when we choose our
      sequence <m>\left(x_n\right)</m> converging to <m>a</m> that
      <m>g(x_n)</m> is not zero?  This would mess up our idea of using
      the corresponding theorem for sequences (<xref
      ref="thm_LimitOfQuotient"></xref> from <xref
      ref="Convergence"></xref>).  This can be handled with the
      following lemma.
    </p>

    <lemma xml:id="lem_BoundedAwayFromZero">
      <statement>
        <p>
          If <m>g</m> is continuous at <m>a</m> and <m>g(a)\neq 0</m>,
          then there exists <m>\delta>0</m> such that <m>g(x)\neq
          0</m> for all <m>x\in(a-\delta,a+\delta)</m>.
        </p>
      </statement>
    </lemma>

    <problem>
      <idx><h>continuous functions</h><h>if <m>f</m> is continuouse and <m>f(a)\neq0</m> then <m>f</m> is bounded away from zero near a</h></idx>    

      <statement>
        <p>
          Prove <xref ref="lem_BoundedAwayFromZero"></xref>.
        </p>
      </statement>
      <hint>
        <p>
          Consider the case where <m>g(a)>0</m>.  Use the definition
          with <m>\eps=\frac{g(a)}{2}</m>.  The picture is below; make
          it formal.
        </p>
        <image width="75%" source="images/Ch5fig8.png" > 
          <shortdescription></shortdescription>
        </image>
        <p>
          For the case <m>g(a)\lt 0</m>, consider the function
          <m>-g</m>.
        </p>
      </hint>
    </problem>

    <p>
      A consequence of this lemma is that if we start with a sequence
      <m>\left(x_n\right)</m> converging to <m>a</m>, then for
      <m>n</m> sufficiently large, <m>g(x_n)\neq 0</m>.
    </p>

    <problem>
      <idx><h>continuous functions</h><h>the quotient of continuous
      functions is continuous</h></idx>

      <statement>
        <p>
          Use <xref ref="thm_LimDefOfContinuity"></xref>, to
          prove that if <m>f</m> and <m>g</m> are continuous at <m>a</m>
          and <m>g(a)\neq 0</m>, then <m>f/g</m> is continuous at
          <m>a</m>.
        </p>
      </statement>
    </problem>

    <theorem xml:id="thm_ContComp">
      <idx><h>continuous functions</h><h>the composition of continuous functions is continuous</h></idx>

      <statement>
        <p>
          Suppose <m>f</m> is continuous at <m>a</m> and <m>g</m> is
          continuous at <m>f(a)</m>.  Then <m>g\circ f</m> is
          continuous at <m>a.</m> (Note that <m>(g\circ
          f)(x)=g(f(x))</m>.)
        </p>
      </statement>
    </theorem>

    <problem>
      <idx><h>continuous functions</h><h>the composition of continuous
      functions is continuous</h></idx>

      <introduction>
        <p>
          Prove <xref ref="thm_ContComp"></xref>
        </p>
      </introduction>
      <task>
        <statement>
          <p>
            Using the definition of continuity.
          </p>
        </statement>
      </task>
      <task>
        <statement>
          <p>
            Using <xref ref="thm_LimDefOfContinuity"></xref>.
          </p>
        </statement>
      </task>
    </problem>

    <p>
      The above theorems allow us to build continuous functions from
      other continuous functions.  For example, knowing that
      <m>f(x)=x</m> and <m>g(x)=c</m> are continuous, we can conclude
      that any polynomial,
      <me>
        p(x)=a_nx^n+a_{n-1}x^{n-1}+\cdots+a_1x+a_0
      </me>
      is continuous as well.  We also know that functions such as
      <m>f(x)=\sin\left(e^x\right)</m> are continuous without having
      to rely on the definition.
    </p>

    <problem>
      <idx><h>continuity</h><h>drill problems</h></idx>
      <introduction>
        <p>
          Show that each of the following is a continuous function at
          every point in its domain.
        </p>
      </introduction>
      <task>
        <statement>
          <p>
            Any polynomial.
          </p>
        </statement>
      </task>
      <task>
        <statement>
          <p>
            Any rational function. (A rational function is defined
            to be a ratio of polynomials.)
          </p>
        </statement>
      </task>
      <task>
        <statement>
          <p>
            <m>\cos x</m>.
          </p>
        </statement>
      </task>
      <task>
        <statement>
          <p>
            The other trig functions: <m>\tan(x)</m>,
            <m>\cot(x)</m>, <m>\sec(x)</m>, and <m>\csc(x)</m>.
          </p>
        </statement>
      </task>
    </problem>

    <problem>
      <idx><h>continuity</h><h><m>\sin e^x</m> is continuous everywhere</h></idx>
      <statement>
        <p>
          What allows us to conclude that
          <m>f(x)=\sin\left(e^x\right)</m> is continuous at any point
          <m>a</m> without referring back to the definition of
          continuity?
        </p>
      </statement>
    </problem>

    <p>
      <xref ref="thm_LimDefOfContinuity"></xref> can also be used
      to study the convergence of sequences.  For example, since
      <m>f(x)=e^x</m> is continuous at any point and
      <m>\limit{n}{\infty}{\frac{n+1}{n}}=1</m>, then
      <m>\limit{n}{\infty}{e^{\left(\frac{n+1}{n}\right)}}=e</m>.
      This also illustrates a certain way of thinking about continuous
      functions.  They are the ones where we can <q>commute</q> the
      function and a limit of a sequence.  Specifically, if <m>f</m> is
      continuous at <m>a</m> and <m>\limit{n}{\infty}{x_n}=a</m>,
      then
      <m>\limit{n}{\infty}{f(x_n)}=f(a)=f\left(\limit{n}{\infty}{x_n}\right)</m>.
    </p>

    <problem>
      <idx><h>continuity</h><h>via sequences</h></idx>
      <introduction>
        <p>
          Compute the following limits.
          Be sure to explain how continuity is involved.
        </p>
      </introduction>
      <task>
        <statement>
          <p>
            <m>\limit{n}{\infty}{\sin\left(\frac{n\pi}{2n+1}\right)}</m>
          </p>
        </statement>
      </task>
      <task>
        <statement>
          <p>
            <m>\limit{n}{\infty}{\sqrt{\frac{n}{n^2+1}}}</m>
          </p>
        </statement>
      </task>
      <task>
        <statement>
          <p>
            <m>\limit{n}{\infty}{e^{\sin (1/n)}}</m>
          </p>
        </statement>
      </task>
    </problem>

    <p>
      Recall that Bolzano<rsq/>s motivation for providing an <xref ref="def_continuity" text="custom">analytic
      definition of continuity</xref>      was to prove the <xref ref="IntermediateValueTheorem" >Intermediate Value
      Theorem</xref>.  We were motivated by the fact that we used the
      Intermediate Value Theorem and the <xref ref="thm_EVT" text="custom">Extreme Value Theorem</xref> in the
      derivation of Lagrange<rsq/>s and Cauchy<rsq/>s forms of the
      remainder for Taylor Series.  Without rigorous proofs of these,
      we have a gap in our understanding of convergence of a Taylor
      series.  In the next chapter, we will close that gap.  In doing
      so we will also need to explore the differences between the
      rational number system and the real number system that we introduced in <xref ref="NumbersRealRational" ></xref>.

      <!-- Our motive for rigorously defining continuity was to resolve the -->
      <!-- apparent discrepencies introduced by Fourier<rsq/>s work. But -->
      <!-- that resolution is still rather distant because we still -->
      <!-- haven<rsq/>t proved the Extreme and Intermediate Value Theorems. -->
      <!-- In the following chapter we will close that gap. -->
    </p>

  </section>


</chapter>

